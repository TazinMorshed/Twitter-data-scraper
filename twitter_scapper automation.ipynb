{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0bb5e1",
   "metadata": {},
   "source": [
    "# Tazin Morshed 01859407926\n",
    "## tazinmorshedshad@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5363b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from getpass import getpass\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb232c99",
   "metadata": {},
   "source": [
    "# How to tweets to extract?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b535a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_TO_EXTRACT = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e32c0",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c2b583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from time import sleep\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "\n",
    "def format_time(time):\n",
    "    f_time = datetime.datetime.strptime(time, '%Y-%m-%dT%H:%M:%S.%f%z').astimezone(ZoneInfo('America/New_York')).strftime('%I:%M %p %d %B, %Y')\n",
    "    return f_time\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def remove_duplicates(x):\n",
    "    return list(dict.fromkeys(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53185feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the retweets \n",
    "# we need to check if retweet = 0, if yes then ignore this loop \n",
    "def return_retweets_info(tweet_url, number_of_retweets, user_tweet):\n",
    "    retwitter_name_list=[]\n",
    "    retwitter_url_list= []\n",
    "    retwitter_tweet_list= []\n",
    "    if number_of_retweets == 0:\n",
    "        retwitter_name_list.append(\"\")\n",
    "        retwitter_url_list.append(\"\")\n",
    "        retwitter_tweet_list.append(\"\")\n",
    "    else: \n",
    "        driver.get(tweet_url)\n",
    "        sleep(3)\n",
    "\n",
    "\n",
    "        go_to_retweets = driver.find_element(\"xpath\", \"//*[@id='react-root']/div/div/div[2]/main/div/div/div/div[1]/div/section/div/div/div[1]/div/div/div[1]/article/div/div/div/div[3]/div[6]/div/div[1]/div/a\").get_attribute('href')\n",
    "        driver.get(go_to_retweets)\n",
    "\n",
    "        sleep(5)\n",
    "\n",
    "        # Need a time delay \n",
    "        scrollable_popup = driver.find_element(By.XPATH, '//*[@id=\"layers\"]/div[2]/div/div/div/div/div/div[2]/div[2]/div/div/div')\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight/3\", scrollable_popup)\n",
    "        sleep(2)\n",
    "\n",
    "        retweets = driver.find_elements(\"xpath\",\"//div[@data-testid='UserCell']\")\n",
    "\n",
    "        #omit the last iteration becuase it shows \"post owner\" retwitted which is not true \n",
    "        for retweet in retweets: #needs tweaking \n",
    "            retwitter_name = retweet.find_element(\"xpath\",\"./div/div[2]/div/div/div/div/a/div\").text\n",
    "            retwitter_url = retweet.find_element(\"xpath\",\"./div/div[2]/div/div/div/div/a\").get_attribute('href')\n",
    "            retwitter_name_list.append(retwitter_name)\n",
    "            retwitter_url_list.append(retwitter_url)\n",
    "            retwitter_tweet_list.append(user_tweet)\n",
    "        \n",
    "    return retwitter_name_list, retwitter_url_list, retwitter_tweet_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "50bff47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect all the comments in the post \n",
    "def collect_comments(tweet_url):  \n",
    "    driver.get(tweet_url)\n",
    "    sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "    no_more_replies = False\n",
    "    while True:\n",
    "        driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "        sleep(2)\n",
    "\n",
    "        try:\n",
    "            show_more_replies = driver.find_element(\"xpath\",\"//*[@id='react-root']/div/div/div[2]/main/div/div/div/div[1]/div/section/div/div/div[30]/div/div/div\")\n",
    "            show_more_replies.click()\n",
    "            sleep(2)\n",
    "        except:\n",
    "            no_more_replies = True\n",
    "\n",
    "        if no_more_replies == True:\n",
    "            break\n",
    "\n",
    "    c_profile_url_list = []\n",
    "    c_name_list = []\n",
    "    c_tweet_list = []\n",
    "    c_tweet_time_list = []\n",
    "\n",
    "\n",
    "    sleep(2)\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight-2000);')\n",
    "    sleep(2)\n",
    "\n",
    "    comments = driver.find_elements(\"xpath\",\".//article[@data-testid='tweet']\")\n",
    "    # while True:\n",
    "    print(\"number of comments: \", len(comments))\n",
    "    sleep(2)\n",
    "    for comment in comments[1:]:\n",
    "\n",
    "        c_profile_url = comment.find_element(\"xpath\", \".//div[@data-testid='User-Names']/div[1]/div/a\").get_attribute('href')\n",
    "        c_profile_url_list.append(c_profile_url)\n",
    "\n",
    "\n",
    "        #C_name\n",
    "        c_name = comment.find_element(\"xpath\", \".//div[@data-testid='User-Names']/div[1]\").text\n",
    "        c_name_list.append(c_name)\n",
    "\n",
    "        #C_tweet\n",
    "        ## exception when no tweet but response is a picture. #retards #If no tweet, just ' '\n",
    "        try: \n",
    "            c_tweet = comment.find_element(By.XPATH, \".//div[@data-testid='tweetText']\").text\n",
    "            c_tweet_list.append(c_tweet)\n",
    "        except:\n",
    "            c_tweet_list.append(\" \") \n",
    "\n",
    "        c_tweet_time = comment.find_element(\"xpath\", \".//div[@data-testid='User-Names']/div[2]/div/div[3]/a/time\").get_attribute('datetime')\n",
    "        c_tweet_time_list.append(format_time(c_tweet_time))\n",
    "    \n",
    "    return c_profile_url_list, c_name_list, c_tweet_list, c_tweet_time_list\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1807957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time\n",
    "\n",
    "#open Microsoft Edge \n",
    "driver = webdriver.Edge()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "31a0b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://twitter.com/login')\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "20799118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "username = driver.find_element(\"xpath\", '//input[@name=\"text\"]')\n",
    "#Enter your twitter user email\n",
    "username.send_keys(\"tazinmorshed@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "71c96a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "username.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8c6b89e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "#type your twitter password\n",
    "my_password = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0adc278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "password = driver.find_element(\"xpath\", '//input[@name=\"password\"]')\n",
    "password.send_keys(my_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c626d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "password.send_keys(Keys.RETURN)\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "080c3d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://twitter.com/bbcbangla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ab60ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "https://twitter.com/bbcbangla/status/1595026347616661504\n",
      "24 93 424\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1595010733447970816\n",
      "  14\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1594993215979286528\n",
      "4 1 40\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1594986657937227776\n",
      "2 2 54\n",
      "\n",
      "12\n",
      "https://twitter.com/bbcbangla/status/1592046061081989121\n",
      "  113\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1591993037940752384\n",
      "1 1 79\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1591989646858375168\n",
      "12 14 352\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1591981584286371840\n",
      "13 25 477\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1591758905578856448\n",
      "11 14 516\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1591722600870203392\n",
      " 7 184\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1591678902820573184\n",
      " 1 82\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1591673977885560832\n",
      "6 18 495\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1591382176322686976\n",
      "2 3 93\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1590717134316806144\n",
      "22 42 695\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1590663763333591040\n",
      "37 32 736\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1590662023826014208\n",
      "87 51 1,425\n",
      "\n",
      "10\n",
      "https://twitter.com/bbcbangla/status/1588406974722543616\n",
      "14 30 441\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1588224954461741056\n",
      "6 14 395\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1588176678664257536\n",
      "135 87 1,224\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1588168369442000898\n",
      "1 2 79\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1588147981949501445\n",
      "3 7 192\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1588119874181763072\n",
      "14 10 227\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1588125422725775362\n",
      "3 2 74\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1588070149676048386\n",
      " 4 120\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1588043719609319424\n",
      " 2 86\n",
      "\n",
      "https://twitter.com/bbcbangla/status/1587710176060022784\n",
      "10 5 315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tweet_link = []\n",
    "number_comments = []\n",
    "number_retweets = []\n",
    "number_likes = []\n",
    "\n",
    "        \n",
    "articles = driver.find_elements(By.XPATH,\"//article[@data-testid='tweet']\")\n",
    "while True:\n",
    "    print(len(articles))\n",
    "   \n",
    "    for article in articles: \n",
    "        no_comments = article.find_element(By.XPATH,\".//div[@data-testid='reply']\").text\n",
    "        no_retweets = article.find_element(By.XPATH,\".//div[@data-testid='retweet']\").text\n",
    "        no_likes = article.find_element(By.XPATH,\".//div[@data-testid='like']\").text\n",
    "        tweets_link =  article.find_element(\"xpath\", \".//div[@data-testid='User-Names']/div[2]/div/div[3]/a\").get_attribute(\"href\")\n",
    "        tweet_link.append(tweets_link)\n",
    "          \n",
    "            \n",
    "        if no_comments == \"\":\n",
    "            number_comments.append(0)\n",
    "        else:\n",
    "            number_comments.append(no_comments)\n",
    "        \n",
    "        if no_retweets == \"\":\n",
    "              number_retweets.append(0)\n",
    "        else:\n",
    "            number_retweets.append(no_retweets)\n",
    "        \n",
    "        if no_likes == \"\":\n",
    "            number_likes.append(0)\n",
    "        else:\n",
    "            number_likes.append(no_likes)\n",
    "      \n",
    "        print(tweets_link)\n",
    "        print(no_comments, no_retweets, no_likes)\n",
    "        print()\n",
    "        \n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    sleep(10)\n",
    "    articles = driver.find_elements(By.XPATH,\"//article[@data-testid='tweet']\")\n",
    "\n",
    "    \n",
    "    tweet_link = remove_duplicates(tweet_link)\n",
    "    \n",
    "    if len(tweet_link) > NUMBER_TO_EXTRACT:\n",
    "        break\n",
    "    \n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3a47b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect all the comments in the post \n",
    "\n",
    "def collect_comments(tweet_url):  \n",
    "    driver.get(tweet_url)\n",
    "    sleep(3)\n",
    "\n",
    "\n",
    "    c_profile_url_list = []\n",
    "    c_name_list = []\n",
    "    c_tweet_list = []\n",
    "    c_tweet_time_list = []\n",
    "\n",
    "\n",
    "\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    sleep(2)\n",
    "\n",
    "    comments = driver.find_elements(\"xpath\",\".//article[@data-testid='tweet']\")\n",
    "    # while True:\n",
    "    print(\"number of comments: \", len(comments))\n",
    "    sleep(2)\n",
    "    for comment in comments[1:]:\n",
    "\n",
    "        c_profile_url = comment.find_element(\"xpath\", \".//div[@data-testid='User-Names']/div[1]/div/a\").get_attribute('href')\n",
    "        c_profile_url_list.append(c_profile_url)\n",
    "\n",
    "\n",
    "        #C_name\n",
    "        c_name = comment.find_element(\"xpath\", \".//div[@data-testid='User-Names']/div[1]\").text\n",
    "        c_name_list.append(c_name)\n",
    "\n",
    "        #C_tweet\n",
    "        ## exception when no tweet but response is a picture. #retards #If no tweet, just ' '\n",
    "        try: \n",
    "            c_tweet = comment.find_element(By.XPATH, \".//div[@data-testid='tweetText']\").text\n",
    "            c_tweet_list.append(c_tweet)\n",
    "        except:\n",
    "            c_tweet_list.append(\" \") \n",
    "        \n",
    "        c_tweet_time = comment.find_element(\"xpath\", \".//div[@data-testid='User-Names']/div[2]/div/div[3]/a/time\").get_attribute('datetime')\n",
    "        c_tweet_time_list.append(format_time(c_tweet_time))\n",
    "    \n",
    "    return c_profile_url_list, c_name_list, c_tweet_list, c_tweet_time_list\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1bf6941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424\n",
      "number of comments:  19\n",
      "14\n",
      "number of comments:  1\n",
      "40\n",
      "number of comments:  3\n",
      "54\n",
      "number of comments:  3\n",
      "113\n",
      "number of comments:  1\n",
      "79\n",
      "number of comments:  2\n",
      "352\n",
      "number of comments:  9\n",
      "477\n",
      "number of comments:  12\n",
      "516\n",
      "number of comments:  10\n",
      "184\n",
      "number of comments:  1\n",
      "82\n",
      "number of comments:  1\n",
      "495\n",
      "number of comments:  8\n",
      "93\n",
      "number of comments:  2\n",
      "695\n",
      "number of comments:  20\n",
      "736\n",
      "number of comments:  20\n",
      "1,425\n",
      "number of comments:  26\n",
      "441\n",
      "number of comments:  12\n",
      "395\n",
      "number of comments:  5\n",
      "1,224\n",
      "number of comments:  29\n",
      "79\n",
      "number of comments:  2\n",
      "192\n",
      "number of comments:  2\n",
      "227\n",
      "number of comments:  1\n",
      "74\n",
      "number of comments:  1\n"
     ]
    }
   ],
   "source": [
    "#Main cell to get all the data \n",
    "user_tweet_list = []\n",
    "user_tweet_time_list = []\n",
    "user_tweet_URL_list= []\n",
    "user_tweet_visuals_list = []\n",
    "\n",
    "c_profile_url_list = []\n",
    "c_name_list = []\n",
    "c_tweet_list = []\n",
    "c_tweet_time_list = []\n",
    "\n",
    "\n",
    "retwitter_name_list = []\n",
    "retwitter_url_list =[]\n",
    "retwitter_text_list =[]\n",
    "\n",
    "no_likes_list=[]\n",
    "\n",
    "\n",
    "iterations = 0 \n",
    "for item, no_rtweets in zip(tweet_link,number_retweets):\n",
    "    \n",
    "    driver.get(item)\n",
    "    sleep(3)\n",
    "    # we dont scape data from threads only tweets for this case \n",
    "    thred = driver.find_element('xpath','//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div[1]/div/div[1]/div[1]/div/div/div/div/div/div[2]/div/h2/span').text\n",
    "    if thred =='Tweet':\n",
    "        user_tweet = driver.find_element(\"xpath\",\"//div[@data-testid='tweetText']\").text\n",
    "        user_tweet_list.append(user_tweet)\n",
    "\n",
    "        user_tweet_time = driver.find_element(\"xpath\", \"//*[@id='react-root']/div/div/div[2]/main/div/div/div/div[1]/div/section/div/div/div[1]/div/div/div[1]/article/div/div/div/div[3]/div[5]/div/div[1]/div/a[1]\").text\n",
    "        user_tweet_time_list.append(user_tweet_time)\n",
    "\n",
    "        user_tweet_URL = driver.find_element(\"xpath\", \"//*[@id='react-root']/div/div/div[2]/main/div/div/div/div[1]/div/section/div/div/div[1]/div/div/div[1]/article/div/div/div/div[3]/div[5]/div/div[1]/div/a[1]\").get_attribute('href')\n",
    "        user_tweet_URL_list.append(user_tweet_URL)\n",
    "\n",
    "        try: #when there is a video \n",
    "            user_tweet_visuals = driver.find_element(\"xpath\",\"//div[@data-testid='card.layoutLarge.media']/a\").get_attribute('href')\n",
    "            user_tweet_visuals_list.append(user_tweet_visuals)\n",
    "        except: \n",
    "            user_tweet_visuals = \" \"\n",
    "            user_tweet_visuals_list.append(user_tweet_visuals)\n",
    "\n",
    "        \n",
    "        no_likes_list.append(number_likes[iterations])\n",
    "        iterations= iterations + 1 \n",
    "      \n",
    "        #fetch all comments \n",
    "        sleep(2)\n",
    "        c_profile_url,c_name,c_tweet,c_tweet_time = collect_comments(item)\n",
    "        c_profile_url_list.append(c_profile_url)\n",
    "        c_name_list.append(c_name)\n",
    "        c_tweet_list.append(c_tweet)\n",
    "        c_tweet_time_list.append(c_tweet_time)\n",
    "\n",
    "        #fetch all retweets\n",
    "        sleep(3)\n",
    "        retwitter_name,retwitter_url,retwitter_text = return_retweets_info(item, no_rtweets, user_tweet)\n",
    "\n",
    "        retwitter_name_list.append(retwitter_name)\n",
    "        retwitter_url_list.append(retwitter_url)\n",
    "        retwitter_text_list.append(retwitter_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f205b0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "#remove the outliers \n",
    "tweet_link = user_tweet_URL_list\n",
    "number_likes = no_likes_list\n",
    "\n",
    "print(len(number_likes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b7faeb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the outliers \n",
    "def clean_list(list1, list2, list3):\n",
    "    list_1 = []\n",
    "    list_2 = []\n",
    "    list_3 = []\n",
    "    \n",
    "    for i,y,z in zip(list1,list2,list3):\n",
    "        if i.strip():\n",
    "            list_1.append(i)\n",
    "            list_2.append(y)\n",
    "            list_3.append(z)\n",
    "\n",
    "    return list_1, list_2, list_3\n",
    "\n",
    "\n",
    "clean_list_1 = []\n",
    "clean_list_2 = []\n",
    "clean_list_3 = []\n",
    "    \n",
    "for i in range(len(retwitter_name_list)):\n",
    "\n",
    "    temp_1, temp_2, temp_3 = clean_list(retwitter_name_list[i],retwitter_url_list[i],retwitter_text_list[i])\n",
    "    clean_list_1.append(temp_1)\n",
    "    clean_list_2.append(temp_2)\n",
    "    clean_list_3.append(temp_3)\n",
    "\n",
    "\n",
    "retwitter_name_list = clean_list_1\n",
    "retwitter_url_list = clean_list_2\n",
    "retwitter_text_list = clean_list_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4bb81b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_comments = []\n",
    "number_retweets = []\n",
    "\n",
    "for i in range(len(retwitter_name_list)):\n",
    "  \n",
    "    number_comments.append(len(c_name_list[i])) \n",
    "    number_retweets.append(len(retwitter_name_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "40f73e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create json \n",
    "\n",
    "list_1 = []\n",
    "for i in range(len(tweet_link)): \n",
    "    dict_1={}\n",
    "    dict_1['tweet_link'] = tweet_link[i]\n",
    "    dict_1['tweet_logistic'] ={}\n",
    "    dict_1['tweet_logistic']['number_of_comments'] = number_comments[i]\n",
    "    dict_1['tweet_logistic']['number_retweets'] = number_retweets[i]\n",
    "    dict_1['tweet_logistic']['number_likes'] = number_likes[i]\n",
    "    \n",
    "    dict_1['tweet_info'] = {}\n",
    "    dict_1['tweet_info']['tweets'] = user_tweet_list[i]\n",
    "    dict_1['tweet_info']['tweet_time'] = user_tweet_time_list[i]\n",
    "    dict_1['tweet_info']['tweet_url'] = user_tweet_URL_list[i]\n",
    "    dict_1['tweet_info']['tweet_visual'] = user_tweet_visuals_list[i]\n",
    "    \n",
    "    dict_1['comments_info'] = {}\n",
    "    dict_1['comments_info']['commenters_name'] = c_name_list[i]\n",
    "    dict_1['comments_info']['commenters_profile'] = c_profile_url_list[i]\n",
    "    dict_1['comments_info']['commenters_tweet'] =  c_tweet_list[i]\n",
    "    dict_1['comments_info']['commenters_tweet_time'] = c_tweet_time_list[i]\n",
    "    \n",
    "    dict_1['retweet_info']= {}\n",
    "    dict_1['retweet_info']['retweeter_name'] = retwitter_name_list[i]\n",
    "    dict_1['retweet_info']['retweet_text']=  retwitter_text_list[i]\n",
    "    dict_1['retweet_info']['retweeter_profile']=retwitter_url_list[i]\n",
    "   \n",
    "    \n",
    "    list_1.append(dict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e8f5b614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet_link': 'https://twitter.com/bbcbangla/status/1594993215979286528',\n",
       " 'tweet_logistic': {'number_of_comments': 2,\n",
       "  'number_retweets': 0,\n",
       "  'number_likes': '40'},\n",
       " 'tweet_info': {'tweets': 'মেসি জানেন, আর্জেন্টিনার হয়ে কাতারে এই বিশ্বকাপ জয় তার ক্যারিয়ারের সেরা জয় হিসেবে স্বীকৃতি পাবে। হয়তো তখন তার ‘সর্বকালের সেরা ফুটবলার’ খেতাব পোক্ত হবে।\\n#FIFAWorldCup #QatarWorldCup2022 #Argentina',\n",
       "  'tweet_time': '3:56 PM · Nov 22, 2022',\n",
       "  'tweet_url': 'https://twitter.com/bbcbangla/status/1594993215979286528',\n",
       "  'tweet_visual': 'https://t.co/ujpcoFxlDk'},\n",
       " 'comments_info': {'commenters_name': ['Anowar hussain', 'Md Shaha Kamal'],\n",
       "  'commenters_profile': ['https://twitter.com/Anowarh27529971',\n",
       "   'https://twitter.com/md_shaha_kamal'],\n",
       "  'commenters_tweet': ['কিন্তু সামনে জার্মানি পড়লে সোজা বিমানের টিকিট হাতে ধরিয়ে দিবে',\n",
       "   'খেলার ধরন খারাপ হয়ে গেছে'],\n",
       "  'commenters_tweet_time': ['05:00 AM 22 November, 2022',\n",
       "   '06:27 AM 22 November, 2022']},\n",
       " 'retweet_info': {'retweeter_name': [],\n",
       "  'retweet_text': [],\n",
       "  'retweeter_profile': []}}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6fe692e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump all data into a json file with indent = 4 \n",
    "import json\n",
    "with open('python_scapper.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(list_1, f ,indent=4, ensure_ascii=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7fa5be5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create separate Dataframes for database entry \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "df = pd.DataFrame(zip(tweet_link,number_comments, number_retweets, number_likes,\n",
    "                     user_tweet_list, user_tweet_time_list, user_tweet_URL_list,user_tweet_visuals_list,\n",
    "                     c_name_list, c_profile_url_list, c_tweet_list,c_tweet_time_list,\n",
    "                     retwitter_name_list, retwitter_url_list),\n",
    "                 columns =[\"tweet_link\",\"no_comments\", \"no_retweets\", \"no_likes\",\n",
    "                          \"user_tweets\", \"user_tweet_time\", \" user_tweet_url\",\n",
    "                          \"user_tweet_visuals\", \"c_name\", \"c_profile\", \"c_tweet\",\n",
    "                          \"c_tweet_time\", \"retweeter_name\", \"retwitter_url\"])\n",
    "\n",
    "\n",
    "df_tweet = pd.DataFrame(zip(tweet_link, number_comments, number_retweets, number_likes),\n",
    "                       columns=['tweet_link', 'no_comments', 'no_retweets','no_likes'])\n",
    "\n",
    "df_user = pd.DataFrame(zip(user_tweet_list,user_tweet_time_list, user_tweet_URL_list, user_tweet_visuals_list),\n",
    "                      columns=['user_tweet','user_tweet_time', \"user_tweet_url\", 'user_tweet_visuals'])\n",
    "                      \n",
    "\n",
    "df_user['Id'] = range(0, len(df_user) )\n",
    "df_tweet['Id'] = range(0, len(df_tweet) )\n",
    "\n",
    "df_user = df_user.astype(str)\n",
    "df_tweet = df_tweet.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f5600a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_user df_tweet df_comment df_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c3da1263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         commenters_name                   commenters_profile  \\\n",
      "0            Anu Mostafa       https://twitter.com/anumostafa   \n",
      "1   GOLAM MOSTOFA SARKER  https://twitter.com/GOLAMMOSTOFASA1   \n",
      "2             abir islam           https://twitter.com/4B1R74   \n",
      "3         Mizanur Rahman  https://twitter.com/Mizanur60484925   \n",
      "4           yeasin hasan     https://twitter.com/hasan_yeasin   \n",
      "..                   ...                                  ...   \n",
      "25       SH Sharif Hasan  https://twitter.com/Khairul35032407   \n",
      "26        Habibur Rahman       https://twitter.com/habiburRBD   \n",
      "27           Nazmul Huda  https://twitter.com/NazmulH51661064   \n",
      "0           Raysha Islam         https://twitter.com/Raysha32   \n",
      "0           Najmul Islam  https://twitter.com/Imnajmulislam11   \n",
      "\n",
      "                                     commenters_tweet  \\\n",
      "0   গোবরে পোকাতেও প্রদীপ নিভিয়ে দিতে পারে। আর্জেন...   \n",
      "1                     মাশা'আল্লাহ \\n\\nইহুদিদের পরাজয়   \n",
      "2   আর্জেন্টিনায় ১০ লাখের বেশী মুসলমান বসবাস করে,...   \n",
      "3   A good news. Great win.\\nCongratulations to th...   \n",
      "4      আলহামদুলিল্লাহ। খেলাটা দেখে মনটা একদম বরে গেছে   \n",
      "..                                                ...   \n",
      "25  ওনার এই কথায় প্রমাণ করে বাংলাদেশের বিচার বিবা...   \n",
      "26                               দেশে আইনের শাসন নেই,   \n",
      "27  Please Send Khaleda Zia to jail,,,,One county ...   \n",
      "0   এটা কে বা কার নির্দেশে হয়েচে,\\nবিবিসি সঠিক ভা...   \n",
      "0               শেহবাজ শরীফের দলের লোকজন এ কাজ করেছে।   \n",
      "\n",
      "         commenters_tweet_time  ID  \n",
      "0   07:53 AM 22 November, 2022   0  \n",
      "1   07:10 AM 22 November, 2022   0  \n",
      "2   07:37 AM 22 November, 2022   0  \n",
      "3   07:14 AM 22 November, 2022   0  \n",
      "4   07:31 AM 22 November, 2022   0  \n",
      "..                         ...  ..  \n",
      "25  02:43 AM 04 November, 2022  18  \n",
      "26  12:51 PM 03 November, 2022  18  \n",
      "27  11:19 AM 03 November, 2022  18  \n",
      "0   10:27 AM 05 November, 2022  19  \n",
      "0   07:23 AM 04 November, 2022  20  \n",
      "\n",
      "[167 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "dtypes = np.dtype(\n",
    "    [\n",
    "        (\"commenters_name\", str),\n",
    "        (\"commenters_profile\", int),\n",
    "        (\"commenters_tweet\", str),\n",
    "        (\"commenters_tweet_time\", str),\n",
    "        ('ID',str)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_comment = pd.DataFrame(np.empty(0, dtype=dtypes))\n",
    "\n",
    "for index, item in enumerate(list_1):\n",
    "    for i in item:\n",
    "        if(i=='comments_info'):\n",
    "            comment_dict = item[i]\n",
    "            df_1 = pd.DataFrame(comment_dict)\n",
    "            df_1['ID'] = index\n",
    "            df_comment = pd.concat([df_comment, df_1])\n",
    "            \n",
    "            \n",
    "print(df_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a7757584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    retweeter_name                                       retweet_text  \\\n",
      "0        Jeanmarie  নিজেদের প্রথম ম্যাচে সৌদি আরবের কাছে হেরে গেল ...   \n",
      "1            Doris  নিজেদের প্রথম ম্যাচে সৌদি আরবের কাছে হেরে গেল ...   \n",
      "2            Molly  নিজেদের প্রথম ম্যাচে সৌদি আরবের কাছে হেরে গেল ...   \n",
      "3             Neda  নিজেদের প্রথম ম্যাচে সৌদি আরবের কাছে হেরে গেল ...   \n",
      "4            Shari  নিজেদের প্রথম ম্যাচে সৌদি আরবের কাছে হেরে গেল ...   \n",
      "..             ...                                                ...   \n",
      "5   Zahir shamsery  পাকিস্তানের সাবেক প্রধানমন্ত্রী ইমরান খানের ওপ...   \n",
      "0   Zahir shamsery  ভারতীয় হাইকমিশনারকে ১৯৭৫ সালে কেন অপহরণ করতে ...   \n",
      "1        Mr Gumede  ভারতীয় হাইকমিশনারকে ১৯৭৫ সালে কেন অপহরণ করতে ...   \n",
      "2   Md Farid uddin  ভারতীয় হাইকমিশনারকে ১৯৭৫ সালে কেন অপহরণ করতে ...   \n",
      "0   Faruk Abdullah  উত্তর কোরিয়া অন্তত দুই ডজন ক্ষেপণাস্ত্র ছোঁড়...   \n",
      "\n",
      "                      retweeter_profile  ID  \n",
      "0   https://twitter.com/Jeanmar40708611   0  \n",
      "1     https://twitter.com/Doris79521423   0  \n",
      "2     https://twitter.com/Molly53159900   0  \n",
      "3      https://twitter.com/Neda12427130   0  \n",
      "4     https://twitter.com/Shari50482054   0  \n",
      "..                                  ...  ..  \n",
      "5          https://twitter.com/shamsery  20  \n",
      "0          https://twitter.com/shamsery  21  \n",
      "1       https://twitter.com/MrGumede153  21  \n",
      "2    https://twitter.com/fariduddin9457  21  \n",
      "0    https://twitter.com/ffarukabdullah  22  \n",
      "\n",
      "[283 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "dtypes = np.dtype(\n",
    "    [\n",
    "        (\"retweeter_name\", str),\n",
    "        (\"retweet_text\", int),\n",
    "        (\"retweeter_profile\", str),\n",
    "        ('ID',str)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_retweet = pd.DataFrame(np.empty(0, dtype=dtypes))\n",
    "\n",
    "for index, item in enumerate(list_1):\n",
    "    for i in item:\n",
    "        if(i=='retweet_info'):\n",
    "            retweet_dict = item[i]\n",
    "            df_1 = pd.DataFrame(retweet_dict)\n",
    "            df_1['ID'] = index\n",
    "            df_retweet = pd.concat([df_retweet, df_1])\n",
    "\n",
    "print(df_retweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8e710349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def collect_comments(tweet_url):  \n",
    "#     driver.get(tweet_url)\n",
    "#     sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "#     no_more_replies = False\n",
    "#     while True:\n",
    "#         driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "#         sleep(2)\n",
    "\n",
    "#         try:\n",
    "#             show_more_replies = driver.find_element(\"xpath\",\"//*[@id='react-root']/div/div/div[2]/main/div/div/div/div[1]/div/section/div/div/div[30]/div/div/div\")\n",
    "#             show_more_replies.click()\n",
    "#             sleep(2)\n",
    "#         except:\n",
    "#             no_more_replies = True\n",
    "\n",
    "#         if no_more_replies == True:\n",
    "#             break\n",
    "\n",
    "#     c_profile_url_list = []\n",
    "#     c_name_list = []\n",
    "#     c_tweet_list = []\n",
    "#     c_tweet_time_list = []\n",
    "\n",
    "\n",
    "#     sleep(2)\n",
    "#     driver.execute_script('window.scrollTo(0,document.body.scrollHeight-2000);')\n",
    "#     sleep(2)\n",
    "\n",
    "#     comments = driver.find_elements(\"xpath\",\".//article[@data-testid='tweet']\")\n",
    "#     # while True:\n",
    "#     print(\"number of comments: \", len(comments))\n",
    "#     sleep(2)\n",
    "#     for comment in comments[1:]:\n",
    "\n",
    "#         c_profile_url = comment.find_element(\"xpath\", \".//div[@data-testid='User-Names']/div[1]/div/a\").get_attribute('href')\n",
    "#         c_profile_url_list.append(c_profile_url)\n",
    "\n",
    "\n",
    "#         #C_name\n",
    "#         c_name = comment.find_element(\"xpath\", \".//div[@data-testid='User-Names']/div[1]\").text\n",
    "#         c_name_list.append(c_name)\n",
    "\n",
    "#         #C_tweet\n",
    "#         ## exception when no tweet but response is a picture. #retards #If no tweet, just ' '\n",
    "#         try: \n",
    "#             c_tweet = comment.find_element(By.XPATH, \".//div[@data-testid='tweetText']\").text\n",
    "#             c_tweet_list.append(c_tweet)\n",
    "#         except:\n",
    "#             c_tweet_list.append(\" \") \n",
    "\n",
    "#         c_tweet_time = comment.find_element(\"xpath\", \".//div[@data-testid='User-Names']/div[2]/div/div[3]/a/time\").get_attribute('datetime')\n",
    "#         c_tweet_time_list.append(format_time(c_tweet_time))\n",
    "    \n",
    "#     return c_profile_url_list, c_name_list, c_tweet_list, c_tweet_time_list\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8372382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\users\\tazin\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: mysql-connector-python in c:\\users\\tazin\\anaconda3\\lib\\site-packages (8.0.31)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.11.0 in c:\\users\\tazin\\anaconda3\\lib\\site-packages (from mysql-connector-python) (3.19.1)\n"
     ]
    }
   ],
   "source": [
    "#need to install\n",
    "!pip install pymysql\n",
    "!pip install mysql-connector-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4f1df1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_tweet</th>\n",
       "      <th>user_tweet_time</th>\n",
       "      <th>user_tweet_url</th>\n",
       "      <th>user_tweet_visuals</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>নিজেদের প্রথম ম্যাচে সৌদি আরবের কাছে হেরে গেল ...</td>\n",
       "      <td>6:08 PM · Nov 22, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159502634...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>বেলিংহাম ইরানের বিপক্ষে ১১৩ বার বল পায়ে নিয়ে...</td>\n",
       "      <td>5:06 PM · Nov 22, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159501073...</td>\n",
       "      <td>https://t.co/IoCodiKEDF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>মেসি জানেন, আর্জেন্টিনার হয়ে কাতারে এই বিশ্বক...</td>\n",
       "      <td>3:56 PM · Nov 22, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159499321...</td>\n",
       "      <td>https://t.co/ujpcoFxlDk</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'আমি যেহেতু কোরিয়াকে ভালোবাসি, সেজন্য আমি ভাল...</td>\n",
       "      <td>3:30 PM · Nov 22, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159498665...</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>মোহাম্মদ শামিকে উদ্দেশ্য করে একজন লিখেছেন “আমর...</td>\n",
       "      <td>12:45 PM · Nov 14, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159204606...</td>\n",
       "      <td>https://t.co/DQnylVPof2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>বলা হচ্ছে এটা রোনালদোর ক্যারিয়ারের 'সবচেয়ে ব...</td>\n",
       "      <td>9:14 AM · Nov 14, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159199303...</td>\n",
       "      <td>https://t.co/3apSIDx7cL</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>পরিবারের ৭২ জন সদস্যকে একই ছাদের নীচে বাস করছে...</td>\n",
       "      <td>9:01 AM · Nov 14, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159198964...</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>আন্তর্জাতিক মুদ্রা তহবিল (আইএমএফ) বলেছে, যেভাব...</td>\n",
       "      <td>8:29 AM · Nov 14, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159198158...</td>\n",
       "      <td>https://t.co/dcS1bWGQGS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>পাকিস্তানকে ৫ উইকেটে হারিয়ে টি-টোয়েন্টি বিশ্...</td>\n",
       "      <td>5:44 PM · Nov 13, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159175890...</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>টেক্সাসে এয়ারশো চলাকালে যে দুই বিমানের সংঘর্ষ...</td>\n",
       "      <td>3:20 PM · Nov 13, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159172260...</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>নিম্নকক্ষ প্রতিনিধি পরিষদে রিপাবলিকানরা সংখ্যা...</td>\n",
       "      <td>12:26 PM · Nov 13, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159167890...</td>\n",
       "      <td>https://t.co/JLxW6bUGeO</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ফরিদপুরের এই সমাবেশে ব্যাপক জনসমাগম হওয়ায় এই...</td>\n",
       "      <td>12:07 PM · Nov 13, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159167397...</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>বনাম  - ফাইনালে বৃষ্টি ও আরো যতো আলোচনার বিষ...</td>\n",
       "      <td>4:47 PM · Nov 12, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159138217...</td>\n",
       "      <td>https://t.co/IAeuRz0O36</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>দুদক থেকে বরখাস্ত শরীফ উদ্দিনের জীবন কেমন কাটছ...</td>\n",
       "      <td>8:44 PM · Nov 10, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159071713...</td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>সরকার পতন, সাজাপ্রাপ্ত নেতার নিঃশর্ত মুক্তির ম...</td>\n",
       "      <td>5:12 PM · Nov 10, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159066376...</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>এইমাত্র পাওয়া: ভারতকে হারিয়ে ফাইনালে ইংল্যান...</td>\n",
       "      <td>5:05 PM · Nov 10, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/159066202...</td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>থাকতেন ইংল্যান্ডের ম্যানচেস্টারের, সেখান থেকে ...</td>\n",
       "      <td>11:45 AM · Nov 4, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/158840697...</td>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'এটা ছিল ইমরান খানকে হত্যা করার একটা প্রচেষ্টা...</td>\n",
       "      <td>11:41 PM · Nov 3, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/158822495...</td>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>জেল হত্যা দিবস উপলক্ষে আয়োজিত এক আলোচনা সভায়...</td>\n",
       "      <td>8:30 PM · Nov 3, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/158817667...</td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ঢাকার কারাগারে আওয়ামী লীগের চারজন শীর্ষ নেতাক...</td>\n",
       "      <td>7:57 PM · Nov 3, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/158816836...</td>\n",
       "      <td>https://t.co/43Zniugntw</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>পাকিস্তানের সাবেক প্রধানমন্ত্রী ইমরান খানের ওপ...</td>\n",
       "      <td>6:35 PM · Nov 3, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/158814798...</td>\n",
       "      <td>https://t.co/Ncb4Ngl2HI</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ভারতীয় হাইকমিশনারকে ১৯৭৫ সালে কেন অপহরণ করতে ...</td>\n",
       "      <td>1:26 PM · Nov 3, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/158807014...</td>\n",
       "      <td>https://t.co/7UdVDoNYYB</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>উত্তর কোরিয়া অন্তত দুই ডজন ক্ষেপণাস্ত্র ছোঁড়...</td>\n",
       "      <td>11:41 AM · Nov 3, 2022</td>\n",
       "      <td>https://twitter.com/bbcbangla/status/158804371...</td>\n",
       "      <td>https://t.co/4oo8hJMV6a</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_tweet  \\\n",
       "0   নিজেদের প্রথম ম্যাচে সৌদি আরবের কাছে হেরে গেল ...   \n",
       "1   বেলিংহাম ইরানের বিপক্ষে ১১৩ বার বল পায়ে নিয়ে...   \n",
       "2   মেসি জানেন, আর্জেন্টিনার হয়ে কাতারে এই বিশ্বক...   \n",
       "3   'আমি যেহেতু কোরিয়াকে ভালোবাসি, সেজন্য আমি ভাল...   \n",
       "4   মোহাম্মদ শামিকে উদ্দেশ্য করে একজন লিখেছেন “আমর...   \n",
       "5   বলা হচ্ছে এটা রোনালদোর ক্যারিয়ারের 'সবচেয়ে ব...   \n",
       "6   পরিবারের ৭২ জন সদস্যকে একই ছাদের নীচে বাস করছে...   \n",
       "7   আন্তর্জাতিক মুদ্রা তহবিল (আইএমএফ) বলেছে, যেভাব...   \n",
       "8   পাকিস্তানকে ৫ উইকেটে হারিয়ে টি-টোয়েন্টি বিশ্...   \n",
       "9   টেক্সাসে এয়ারশো চলাকালে যে দুই বিমানের সংঘর্ষ...   \n",
       "10  নিম্নকক্ষ প্রতিনিধি পরিষদে রিপাবলিকানরা সংখ্যা...   \n",
       "11  ফরিদপুরের এই সমাবেশে ব্যাপক জনসমাগম হওয়ায় এই...   \n",
       "12    বনাম  - ফাইনালে বৃষ্টি ও আরো যতো আলোচনার বিষ...   \n",
       "13  দুদক থেকে বরখাস্ত শরীফ উদ্দিনের জীবন কেমন কাটছ...   \n",
       "14  সরকার পতন, সাজাপ্রাপ্ত নেতার নিঃশর্ত মুক্তির ম...   \n",
       "15  এইমাত্র পাওয়া: ভারতকে হারিয়ে ফাইনালে ইংল্যান...   \n",
       "16  থাকতেন ইংল্যান্ডের ম্যানচেস্টারের, সেখান থেকে ...   \n",
       "17  'এটা ছিল ইমরান খানকে হত্যা করার একটা প্রচেষ্টা...   \n",
       "18  জেল হত্যা দিবস উপলক্ষে আয়োজিত এক আলোচনা সভায়...   \n",
       "19  ঢাকার কারাগারে আওয়ামী লীগের চারজন শীর্ষ নেতাক...   \n",
       "20  পাকিস্তানের সাবেক প্রধানমন্ত্রী ইমরান খানের ওপ...   \n",
       "21  ভারতীয় হাইকমিশনারকে ১৯৭৫ সালে কেন অপহরণ করতে ...   \n",
       "22  উত্তর কোরিয়া অন্তত দুই ডজন ক্ষেপণাস্ত্র ছোঁড়...   \n",
       "\n",
       "            user_tweet_time  \\\n",
       "0    6:08 PM · Nov 22, 2022   \n",
       "1    5:06 PM · Nov 22, 2022   \n",
       "2    3:56 PM · Nov 22, 2022   \n",
       "3    3:30 PM · Nov 22, 2022   \n",
       "4   12:45 PM · Nov 14, 2022   \n",
       "5    9:14 AM · Nov 14, 2022   \n",
       "6    9:01 AM · Nov 14, 2022   \n",
       "7    8:29 AM · Nov 14, 2022   \n",
       "8    5:44 PM · Nov 13, 2022   \n",
       "9    3:20 PM · Nov 13, 2022   \n",
       "10  12:26 PM · Nov 13, 2022   \n",
       "11  12:07 PM · Nov 13, 2022   \n",
       "12   4:47 PM · Nov 12, 2022   \n",
       "13   8:44 PM · Nov 10, 2022   \n",
       "14   5:12 PM · Nov 10, 2022   \n",
       "15   5:05 PM · Nov 10, 2022   \n",
       "16   11:45 AM · Nov 4, 2022   \n",
       "17   11:41 PM · Nov 3, 2022   \n",
       "18    8:30 PM · Nov 3, 2022   \n",
       "19    7:57 PM · Nov 3, 2022   \n",
       "20    6:35 PM · Nov 3, 2022   \n",
       "21    1:26 PM · Nov 3, 2022   \n",
       "22   11:41 AM · Nov 3, 2022   \n",
       "\n",
       "                                       user_tweet_url  \\\n",
       "0   https://twitter.com/bbcbangla/status/159502634...   \n",
       "1   https://twitter.com/bbcbangla/status/159501073...   \n",
       "2   https://twitter.com/bbcbangla/status/159499321...   \n",
       "3   https://twitter.com/bbcbangla/status/159498665...   \n",
       "4   https://twitter.com/bbcbangla/status/159204606...   \n",
       "5   https://twitter.com/bbcbangla/status/159199303...   \n",
       "6   https://twitter.com/bbcbangla/status/159198964...   \n",
       "7   https://twitter.com/bbcbangla/status/159198158...   \n",
       "8   https://twitter.com/bbcbangla/status/159175890...   \n",
       "9   https://twitter.com/bbcbangla/status/159172260...   \n",
       "10  https://twitter.com/bbcbangla/status/159167890...   \n",
       "11  https://twitter.com/bbcbangla/status/159167397...   \n",
       "12  https://twitter.com/bbcbangla/status/159138217...   \n",
       "13  https://twitter.com/bbcbangla/status/159071713...   \n",
       "14  https://twitter.com/bbcbangla/status/159066376...   \n",
       "15  https://twitter.com/bbcbangla/status/159066202...   \n",
       "16  https://twitter.com/bbcbangla/status/158840697...   \n",
       "17  https://twitter.com/bbcbangla/status/158822495...   \n",
       "18  https://twitter.com/bbcbangla/status/158817667...   \n",
       "19  https://twitter.com/bbcbangla/status/158816836...   \n",
       "20  https://twitter.com/bbcbangla/status/158814798...   \n",
       "21  https://twitter.com/bbcbangla/status/158807014...   \n",
       "22  https://twitter.com/bbcbangla/status/158804371...   \n",
       "\n",
       "         user_tweet_visuals  Id  \n",
       "0                             0  \n",
       "1   https://t.co/IoCodiKEDF   1  \n",
       "2   https://t.co/ujpcoFxlDk   2  \n",
       "3                             3  \n",
       "4   https://t.co/DQnylVPof2   4  \n",
       "5   https://t.co/3apSIDx7cL   5  \n",
       "6                             6  \n",
       "7   https://t.co/dcS1bWGQGS   7  \n",
       "8                             8  \n",
       "9                             9  \n",
       "10  https://t.co/JLxW6bUGeO  10  \n",
       "11                           11  \n",
       "12  https://t.co/IAeuRz0O36  12  \n",
       "13                           13  \n",
       "14                           14  \n",
       "15                           15  \n",
       "16                           16  \n",
       "17                           17  \n",
       "18                           18  \n",
       "19  https://t.co/43Zniugntw  19  \n",
       "20  https://t.co/Ncb4Ngl2HI  20  \n",
       "21  https://t.co/7UdVDoNYYB  21  \n",
       "22  https://t.co/4oo8hJMV6a  22  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user \n",
    "# df_tweet \n",
    "# df_comment\n",
    "# df_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "426de8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're connected to database:  ('twitter_data_db',)\n",
      "Table is created....\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n"
     ]
    }
   ],
   "source": [
    "#create table and insert documents \n",
    "\n",
    "import mysql.connector as msql\n",
    "from mysql.connector import Error\n",
    "\n",
    "try:\n",
    "    conn = msql.connect(host='localhost', user='root',database='twitter_data_db', \n",
    "                        password='1234dota')#give ur username, password\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "        cursor.execute('DROP TABLE IF EXISTS employee_data;')\n",
    "   \n",
    "               \n",
    "        cursor.execute(\"CREATE TABLE tweet(tweet_link varchar(255),number_of_comments varchar(255),number_of_retweets varchar(255),number_of_likes varchar(255), Id int)\")\n",
    "        print(\"Table is created....\")\n",
    "        conn.commit()\n",
    "        \n",
    "        \n",
    "        sleep(2) \n",
    "        \n",
    "        for i, row in df_tweet.iterrows():\n",
    "            sql ='INSERT INTO twitter_data_db.tweet VALUES (%s,%s,%s,%s,%s)'\n",
    "            cursor.execute(sql,tuple(row))\n",
    "            print(\"record inserted\")\n",
    "            conn.commit()\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f913dd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're connected to database:  ('twitter_data_db',)\n",
      "Table is created....\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "Error while connecting to MySQL 1406 (22001): Data too long for column 'user_tweet' at row 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import mysql.connector as msql\n",
    "from mysql.connector import Error\n",
    "\n",
    "try:\n",
    "    conn = msql.connect(host='localhost', user='root',database='twitter_data_db', \n",
    "                        password='1234dota')#give ur username, password\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "        cursor.execute('DROP TABLE IF EXISTS employee_data;')\n",
    "   \n",
    "\n",
    "        \n",
    "        cursor.execute(\"CREATE TABLE user_data(user_tweet varchar(255),user_tweet_time varchar(255),user_tweet_url varchar(255),user_tweet_visuals varchar(255), Id int)\")\n",
    "        print(\"Table is created....\")\n",
    "        conn.commit()\n",
    "        \n",
    "        for i, row in df_user.iterrows():\n",
    "            sql ='INSERT INTO twitter_data_db.user_data VALUES (%s,%s,%s,%s, %s)'\n",
    "            cursor.execute(sql,tuple(row))\n",
    "            print(\"record inserted\")\n",
    "            conn.commit()\n",
    "            \n",
    "      \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4c42fce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're connected to database:  ('twitter_data_db',)\n",
      "Table is created....\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "Error while connecting to MySQL 1406 (22001): Data too long for column 'tweet' at row 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import mysql.connector as msql\n",
    "from mysql.connector import Error\n",
    "\n",
    "try:\n",
    "    conn = msql.connect(host='localhost', user='root',database='twitter_data_db', \n",
    "                        password='1234dota')#give ur username, password\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "        cursor.execute('DROP TABLE IF EXISTS employee_data;')\n",
    "   \n",
    "\n",
    "      \n",
    "    \n",
    "        cursor.execute(\"CREATE TABLE comment_data(name varchar(255),profile_url varchar(255),tweet varchar(255),tweet_time varchar(255), Id int)\")\n",
    "        print(\"Table is created....\")\n",
    "        conn.commit() \n",
    "        \n",
    "        for i, row in df_comment.iterrows():\n",
    "            sql ='INSERT INTO twitter_data_db.comment_data VALUES (%s,%s,%s,%s,%s)'\n",
    "            cursor.execute(sql,tuple(row))\n",
    "            print(\"record inserted\")   \n",
    "            conn.commit()\n",
    "            \n",
    "        \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c1423614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're connected to database:  ('twitter_data_db',)\n",
      "Table is created....\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "record inserted\n",
      "Error while connecting to MySQL 1406 (22001): Data too long for column 'retweet_text' at row 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import mysql.connector as msql\n",
    "from mysql.connector import Error\n",
    "\n",
    "try:\n",
    "    conn = msql.connect(host='localhost', user='root',database='twitter_data_db', \n",
    "                        password='1234dota')#give ur username, password\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "        cursor.execute('DROP TABLE IF EXISTS employee_data;')\n",
    "   \n",
    "\n",
    "        \n",
    "\n",
    " \n",
    "     \n",
    "        cursor.execute(\"CREATE TABLE retweet_data(name varchar(255), retweet_text varchar(255), profile_url varchar(255), Id int)\")\n",
    "        print(\"Table is created....\")\n",
    "        conn.commit() \n",
    "            \n",
    "        for i, row in df_retweet.iterrows():\n",
    "            sql ='INSERT INTO twitter_data_db.retweet_data VALUES (%s,%s,%s,%s)'\n",
    "            cursor.execute(sql,tuple(row))\n",
    "            print(\"record inserted\")\n",
    "            conn.commit()\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d2bf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
